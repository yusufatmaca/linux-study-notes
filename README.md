# Linux Study Notes
This repository documents my ongoing journey of exploring Linux â€” not just as a collection of commands, but as a deeper understanding of how Unix-like systems work.

Here, you'll find:
- My personal notes
- Experiments, scripts, and exercises
- Resources Iâ€™ve collected along the way

Sometimes I dive into internals like processes, filesystems, and system calls. Other times, I pause at a more abstract level â€” learning philosophies, best practices, and workflows that shape the Linux ecosystem.

The aim isnâ€™t just to learn *how* to use Linux tools, but *why* they exist and *how* they fit into building reliable, efficient systems.

Feel free to browse, fork, or use this as inspiration for your own Linux journey. âœ¨

You can access some video resources I utilize by clicking [here](https://youtube.com/playlist?list=PLdjez6AOp0txwUZsmfqPJi7zViMnQwT2X&si=ClEWqs3pPibFXpG9).

---

## Text Processing
One of the key reasons Linux is so powerful is its philosophy of building small, composable tools that work with plain text. Text is a universal interface: logs, configuration files, command outputs, and scripts all rely on it. 

Effective text processing skills allow us to transform, extract, analyze, and automate almost any kind of data-driven task directly from the command line â€” often without writing a full program.

In this section, I explore essential text processing tools, especially:

- ðŸ”§ `cut`
- ðŸ”§ `awk`
- ðŸ”§ `sed`

These tools embody the Unix philosophy:
> *"Write programs that do one thing and do it well. Write programs to work together. Write programs to handle text streams, because that is a universal interface."*

Together, `cut`, `awk`, and `sed` form a **powerful toolkit for efficient text manipulation, automation, and data wrangling directly from the command line**.
